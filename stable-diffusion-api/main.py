"""
Stable Diffusion 3.5 Medium API Server
–õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Stable Diffusion 3.5 Medium
"""
import base64
import io
import os
from concurrent.futures import ThreadPoolExecutor
from typing import Optional

import torch
from diffusers import StableDiffusionPipeline
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

app = FastAPI(title="Stable Diffusion 3.5 Medium API")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞
pipe = None
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üîß Using device: {device}")

# Thread pool –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
executor = ThreadPoolExecutor(max_workers=1)

# –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–∫—Ä—ã—Ç—É—é –º–æ–¥–µ–ª—å, –Ω–µ —Ç—Ä–µ–±—É—é—â—É—é –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)
MODEL_ID = "runwayml/stable-diffusion-v1-5"


class GenerateRequest(BaseModel):
    prompt: str
    reference_image: Optional[str] = None  # Base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    num_inference_steps: int = 28
    guidance_scale: float = 7.0
    width: int = 1024
    height: int = 1024


class GenerateResponse(BaseModel):
    imageUrl: str  # Base64 data URL
    error: Optional[str] = None


def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Stable Diffusion 3.5 Medium"""
    global pipe
    if pipe is not None:
        return pipe

    print(f"üì¶ Loading model: {MODEL_ID}")
    print("‚è≥ This may take a few minutes on first run...")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω (Stable Diffusion 2.1 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç StableDiffusionPipeline)
        from diffusers import StableDiffusionPipeline
        
        pipe = StableDiffusionPipeline.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        )
        pipe = pipe.to(device)

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        if device == "cuda":
            pipe.enable_attention_slicing()
            pipe.enable_vae_slicing()

        print("‚úÖ Model loaded successfully")
        return pipe
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        raise


@app.on_event("startup")
async def startup_event():
    """–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)"""
    print("‚úÖ Server started. Model will be loaded on first request.")


@app.get("/health")
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "ok",
        "model_loaded": pipe is not None,
        "device": device,
    }


@app.post("/generate", response_model=GenerateResponse)
async def generate_image(request: GenerateRequest):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –ø—Ä–æ–º–ø—Ç—É
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-image –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω reference_image
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å)
        if pipe is None:
            print("üì¶ Loading model in background thread...")
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            future = executor.submit(load_model)
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
            future.result(timeout=300)  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
            print("‚úÖ Model loaded, proceeding with generation")

        print(f"üé® Generating image with prompt: {request.prompt[:100]}...")
        print(f"üì∑ Has reference image: {request.reference_image is not None}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
        def generate():
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if request.reference_image:
                # Image-to-image —Ä–µ–∂–∏–º
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
                if request.reference_image.startswith("data:"):
                    # –£–±–∏—Ä–∞–µ–º data URL –ø—Ä–µ—Ñ–∏–∫—Å
                    base64_data = request.reference_image.split(",")[1]
                else:
                    base64_data = request.reference_image

                image_bytes = base64.b64decode(base64_data)
                from PIL import Image
                reference_img = Image.open(io.BytesIO(image_bytes))

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–º
                print("üì∑ Using reference image (image-to-image mode)")
                return pipe(
                    prompt=request.prompt,
                    num_inference_steps=request.num_inference_steps,
                    guidance_scale=request.guidance_scale,
                    width=request.width,
                    height=request.height,
                )
            else:
                # Text-to-image —Ä–µ–∂–∏–º
                print("üìù Text-to-image mode")
                return pipe(
                    prompt=request.prompt,
                    num_inference_steps=request.num_inference_steps,
                    guidance_scale=request.guidance_scale,
                    width=request.width,
                    height=request.height,
                )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        future = executor.submit(generate)
        result = future.result(timeout=300)  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é

        # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = result.images[0]

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()

        # –§–æ—Ä–º–∏—Ä—É–µ–º data URL
        image_url = f"data:image/png;base64,{img_base64}"

        print("‚úÖ Image generated successfully")
        return GenerateResponse(imageUrl=image_url)

    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå Error generating image: {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)


if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", "7861"))
    uvicorn.run(app, host="0.0.0.0", port=port)

